{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dto-uOuWSZIE"
      },
      "source": [
        "# Mask R-CNN - Train pods dataset\n",
        "\n",
        "\n",
        "This notebook shows how to train Mask R-CNN implemented on coco on your own dataset. The current code segments pods objects in an image. You'd need a GPU, because the network backbone is a Resnet50, which would be too slow to train on a CPU. On google colab you can start to get okay-ish results in a few minutes, and good results in less than an hour."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEbCSM2KsVS9"
      },
      "outputs": [],
      "source": [
        "!rm -rf pods_dataset/\n",
        "!rm -rf sample_data/\n",
        "!rm -rf logs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9IIRSdUcbW2"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==1.13.1\n",
        "!pip install keras==2.2.5\n",
        "!pip install imgaug==0.4.0\n",
        "!pip install scikit-image==0.16.2\n",
        "!pip install h5py==2.10.0\n",
        "!pip install numpy==1.18.5\n",
        "!pip install mrcnn-colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUv2fZL5WgFN"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/barbaraport/pods_dataset.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaHtb9hysSPJ"
      },
      "outputs": [],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8eAPTNTuTYD"
      },
      "outputs": [],
      "source": [
        "!pip show keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPQLeVZNoofS"
      },
      "outputs": [],
      "source": [
        "!pip show tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMwapxaFSZIH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import pandas as pd\n",
        "import skimage\n",
        "\n",
        "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
        "from skimage.transform import resize\n",
        "\n",
        "from mrcnn.config import Config\n",
        "import mrcnn.utils as utils\n",
        "import mrcnn.model as modellib\n",
        "import mrcnn.visualize as visualize\n",
        "from mrcnn.model import log\n",
        "\n",
        "import imgaug.augmenters as iaa\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "# Data Path\n",
        "TRAIN_PATH = 'pods_dataset/trainData/stage2_train/'\n",
        "TEST_PATH = 'pods_dataset/trainData/stage2_test/'\n",
        "\n",
        "# Get train and test IDs\n",
        "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
        "test_ids = next(os.walk(TEST_PATH))[1]\n",
        "\n",
        "%matplotlib inline \n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.getcwd()\n",
        "\n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "# Local path to trained weights file\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "# Download COCO trained weights from Releases if needed\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    utils.download_trained_weights(COCO_MODEL_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpT9HgC7SZIN"
      },
      "source": [
        "## Configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBONWUhASZIO"
      },
      "outputs": [],
      "source": [
        "class ShapesConfig(Config):\n",
        "    \"\"\"Configuration for training on the dataset.\n",
        "    Derives from the base Config class and overrides values specific\n",
        "    to the dataset.\n",
        "    \"\"\"\n",
        "    BACKBONE = \"resnet50\"\n",
        "\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = \"shapes\"\n",
        "\n",
        "    # Train on 1 GPU and 1 images per GPU. We can put multiple images on each\n",
        "    # GPU. Batch size is (GPUs * images/GPU).\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "    BATCH_SIZE = 32\n",
        "\n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 2\n",
        "\n",
        "    # Steps per epoch \n",
        "    STEPS_PER_EPOCH = 100\n",
        "\n",
        "    # Image resize mode\n",
        "    # No changes to the image\n",
        "    IMAGE_RESIZE_MODE = \"none\"\n",
        "    IMAGE_MAX_DIM = 1024\n",
        "    IMAGE_MIN_DIM = 1024\n",
        "\n",
        "    # Minimum probability value to accept a detected instance\n",
        "    # ROIs below this threshold are skipped\n",
        "    DETECTION_MIN_CONFIDENCE = 0.6\n",
        "\n",
        "    # Non-maximum suppression threshold for detection\n",
        "    DETECTION_NMS_THRESHOLD = 0.1\n",
        "\n",
        "    # Length of square anchor side in pixels\n",
        "    RPN_ANCHOR_SCALES = (4, 8, 16, 32, 64)\n",
        "\n",
        "    # Non-max suppression threshold to filter RPN proposals.\n",
        "    # You can increase this during training to generate more proposals.\n",
        "    RPN_NMS_THRESHOLD = 0.1\n",
        "\n",
        "    \n",
        "config = ShapesConfig()\n",
        "config.display()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dhvNUELSZIS"
      },
      "source": [
        "## Notebook Preferences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sj3zh7wMSZIW"
      },
      "outputs": [],
      "source": [
        "def get_ax(rows=1, cols=1, size=8):\n",
        "    \"\"\"Return a Matplotlib Axes array to be used in\n",
        "    all visualizations in the notebook. Provide a\n",
        "    central point to control graph sizes.\n",
        "    \n",
        "    Change the default size attribute to control the size\n",
        "    of rendered images\n",
        "    \"\"\"\n",
        "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
        "    return ax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjEu-7I1SZIY"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "Create a synthetic dataset\n",
        "\n",
        "Extend the Dataset class and add a method to load the shapes dataset, `load_shapes()`, and override the following methods:\n",
        "\n",
        "* load_image()\n",
        "* load_mask()\n",
        "* image_reference()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqkR3-OHSZIY"
      },
      "outputs": [],
      "source": [
        "class ShapesDataset(utils.Dataset):\n",
        "    \n",
        "    def load_shapes(self, mode, is_train=True):\n",
        "        self.add_class(\"shapes\", 1, \"pod\")\n",
        "        \n",
        "        images_dir = TRAIN_PATH + \"images/\"\n",
        "        annotations_dir = TRAIN_PATH + \"annotations/\"\n",
        "\n",
        "        if not is_train:\n",
        "            images_dir = TEST_PATH + \"images/\"\n",
        "            annotations_dir = TEST_PATH + \"annotations/\"\n",
        "\n",
        "        filenames = os.listdir(images_dir)\n",
        "        files_quantity = len(filenames)\n",
        "\n",
        "        for i in range(files_quantity):\n",
        "            filename = filenames[i]\n",
        "            image_id = i\n",
        "            \n",
        "            image_path = images_dir + filename\n",
        "            annotation_path = annotations_dir + filename[:-4] + '.json'\n",
        "\n",
        "            annotation = json.load(open(os.path.join(annotation_path)))\n",
        "\n",
        "            shapes = [] \n",
        "            class_ids = []\n",
        "            labels_list = []\n",
        "\n",
        "            for shape in annotation[\"shapes\"]:\n",
        "                label = shape[\"label\"]\n",
        "                if labels_list.count(label) == 0:\n",
        "                    labels_list.append(label)\n",
        "                class_ids.append(labels_list.index(label)+1)\n",
        "                points = shape[\"points\"]\n",
        "                shapes.append(points)\n",
        "            \n",
        "            width = annotation[\"imageWidth\"]\n",
        "            height = annotation[\"imageHeight\"]\n",
        "            \n",
        "            self.add_image('shapes', image_id = image_id, path = image_path, annotation = annotation_path, width = width, height = height, shapes = shapes, class_ids = class_ids)\n",
        "            i += 1   \n",
        "\n",
        "    def load_image(self, image_id):\n",
        "        \n",
        "        info = self.image_info[image_id]\n",
        "        path = info.get(\"path\")\n",
        "\n",
        "        img = imread(path)[:,:,:3]\n",
        "        img = resize(img, (config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1]), mode='constant', preserve_range=True)\n",
        "       \n",
        "        return img\n",
        "\n",
        "    def image_reference(self, image_id):\n",
        "        info = self.image_info[image_id]\n",
        "        if info[\"source\"] == \"shapes\":\n",
        "            return info[\"shapes\"]\n",
        "        else:\n",
        "            super(self.__class__).image_reference(self, image_id)\n",
        "\n",
        "    def load_mask(self, image_id):\n",
        "        info = self.image_info[image_id]\n",
        "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"shapes\"])], dtype=np.uint8)\n",
        "\n",
        "        for idx, points in enumerate(info[\"shapes\"]):\n",
        "            pointsy, pointsx = zip(*points)\n",
        "            rr, cc = skimage.draw.polygon(pointsx, pointsy)\n",
        "            mask[rr, cc, idx] = 1\n",
        "\n",
        "        masks_np = mask.astype(np.bool)\n",
        "        classids_np = np.array(info[\"class_ids\"]).astype(np.int32)\n",
        "        \n",
        "        return masks_np, classids_np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAhNtW_TSZIb"
      },
      "outputs": [],
      "source": [
        "# Training dataset\n",
        "dataset_train = ShapesDataset()\n",
        "dataset_train.load_shapes('shapes', is_train=True)\n",
        "dataset_train.prepare()\n",
        "print('Train: %d' % len(dataset_train.image_ids))\n",
        "\n",
        "# Validation dataset\n",
        "dataset_val = ShapesDataset()\n",
        "dataset_val.load_shapes('shapes', is_train=False)\n",
        "dataset_val.prepare()\n",
        "print('Validation: %d' % len(dataset_val.image_ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAizzQC5SZIf"
      },
      "outputs": [],
      "source": [
        "# Load and display random samples\n",
        "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
        "for image_id in image_ids:\n",
        "    image = dataset_train.load_image(image_id)\n",
        "    mask, class_ids = dataset_train.load_mask(image_id)\n",
        "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyEQKAnMSZIi"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GCYogpmSZIj"
      },
      "outputs": [],
      "source": [
        "# Create model in training mode\n",
        "model = modellib.MaskRCNN(mode=\"training\", config=config,model_dir=MODEL_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUuC-fI4SZIl"
      },
      "outputs": [],
      "source": [
        "# Which weights to start with?\n",
        "init_with = \"coco\"  # imagenet, coco, or last\n",
        "\n",
        "if init_with == \"imagenet\":\n",
        "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
        "elif init_with == \"coco\":\n",
        "    model.load_weights(\"mask_rcnn_coco.h5\", by_name=True,\n",
        "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "elif init_with == \"last\":\n",
        "    # Load the last model you trained and continue training\n",
        "    model.load_weights(\"mask_rcnn_shapes_0006.h5\", by_name=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzZuQxylSZIo"
      },
      "source": [
        "## Training\n",
        "\n",
        "Train in two stages:\n",
        "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
        "\n",
        "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nuTxwO_XFiL"
      },
      "outputs": [],
      "source": [
        "augmentation = iaa.Sequential([\n",
        "    iaa.Fliplr(0.5),\n",
        "    iaa.Crop(percent=(0, 0.1)),\n",
        "    iaa.Affine(\n",
        "        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
        "        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
        "        rotate=(-25, 25),\n",
        "        shear=(-8, 8)\n",
        "    )\n",
        "], random_order=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2jmfqdLSZIp"
      },
      "outputs": [],
      "source": [
        "model.train(dataset_train, dataset_val,\n",
        "    learning_rate=config.LEARNING_RATE,\n",
        "    epochs=5,\n",
        "    layers='heads',\n",
        "    augmentation=augmentation\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "quEQ2IzJauP2"
      },
      "outputs": [],
      "source": [
        "model.train(dataset_train, dataset_val,\n",
        "    learning_rate=config.LEARNING_RATE,\n",
        "    epochs=20,\n",
        "    layers='all',\n",
        "    augmentation=augmentation\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MG8lGckkODGY"
      },
      "outputs": [],
      "source": [
        "%reload_ext tensorboard.notebook\n",
        "%load_ext tensorboard.notebook\n",
        "%tensorboard --logdir logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldulTQXRSZI0"
      },
      "source": [
        "## Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWhUidKESZI1"
      },
      "outputs": [],
      "source": [
        "class InferenceConfig(ShapesConfig):\n",
        "    NAME = \"eS_inference\"\n",
        "\n",
        "inference_config = InferenceConfig()\n",
        "inference_config.display()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mC2zbO7uB2K"
      },
      "outputs": [],
      "source": [
        "# Recreate the model in inference mode\n",
        "model = modellib.MaskRCNN(mode=\"inference\", \n",
        "                          config=inference_config,\n",
        "                          model_dir=MODEL_DIR)\n",
        "\n",
        "# Get path to saved weights\n",
        "# Either set a specific path or find last trained weights\n",
        "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
        "# model_path = model.find_last()[1]\n",
        "model_path = \"mask_rcnn_shapes_0001.h5\"\n",
        "\n",
        "# Load trained weights (fill in path to trained weights here)\n",
        "assert model_path != \"\", \"Provide path to trained weights\"\n",
        "print(\"Loading weights from \", model_path)\n",
        "model.load_weights(model_path, by_name=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-aJVKAhSZI3"
      },
      "outputs": [],
      "source": [
        "test_image = \"random\" # Choose random or provide an image path\n",
        "\n",
        "if test_image == \"random\":\n",
        "    # Test on a random image\n",
        "    image_id = random.choice(dataset_val.image_ids)\n",
        "    original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "        modellib.load_image_gt(dataset_val, inference_config, \n",
        "                            image_id, use_mini_mask=False)\n",
        "        \n",
        "    log(\"original_image\", original_image)\n",
        "    log(\"image_meta\", image_meta)\n",
        "    log(\"gt_class_id\", gt_class_id)\n",
        "    log(\"gt_bbox\", gt_bbox)\n",
        "    log(\"gt_mask\", gt_mask)\n",
        "\n",
        "    visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, dataset_train.class_names, figsize=(8, 8))\n",
        "else:\n",
        "    assert test_image != \"\", \"Choose the type of test\"\n",
        "    assert test_image != \"random\", \"Please, provide an image path\"\n",
        "    original_image = cv2.imread(test_image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyAT1glESZI7"
      },
      "outputs": [],
      "source": [
        "results = model.detect([original_image], verbose=1)\n",
        "\n",
        "r = results[0]\n",
        "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            dataset_val.class_names, r['scores'], ax=get_ax())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8mN9BsDSZI-"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHLQyFbRc3RG"
      },
      "outputs": [],
      "source": [
        "IOU_THRESHOLD = 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Df1AxrXzcCfq"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WojeZdwRxEU1"
      },
      "source": [
        "### Confusion Matrix code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsEZ-i4smNsj"
      },
      "outputs": [],
      "source": [
        "\"\"\" \n",
        "Licence : AIT JEDDI Yassine\n",
        "Objectif : compute a confusion matrix for the whole test dataset\n",
        "Reference : https://github.com/matterport/Mask_RCNN/\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "Note : copy this code in your original ulils.py file.\n",
        "\"\"\"\n",
        "from pandas import DataFrame\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "from matplotlib.collections import QuadMesh\n",
        "import seaborn as sn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from pandas import DataFrame\n",
        "from string import ascii_uppercase\n",
        "\n",
        "def get_iou(a, b, epsilon=1e-5):\n",
        "    \"\"\" \n",
        "    Given two boxes `a` and `b` defined as a list of four numbers:\n",
        "            [x1,y1,x2,y2]\n",
        "        where:\n",
        "            x1,y1 represent the upper left corner\n",
        "            x2,y2 represent the lower right corner\n",
        "        It returns the Intersect of Union score for these two boxes.\n",
        "    Args: \n",
        "        a:          (list of 4 numbers) [x1,y1,x2,y2]\n",
        "        b:          (list of 4 numbers) [x1,y1,x2,y2]\n",
        "        epsilon:    (float) Small value to prevent division by zero\n",
        "    Returns:\n",
        "        (float) The Intersect of Union score.\n",
        "    \"\"\"\n",
        "    \n",
        "    x1 = max(a[0], b[0])\n",
        "    y1 = max(a[1], b[1])\n",
        "    x2 = min(a[2], b[2])\n",
        "    y2 = min(a[3], b[3])\n",
        "\n",
        "    width = (x2 - x1)\n",
        "    height = (y2 - y1)\n",
        "    \n",
        "    if (width<0) or (height <0):\n",
        "        return 0.0\n",
        "    area_overlap = width * height\n",
        "\n",
        "    area_a = (a[2] - a[0]) * (a[3] - a[1])\n",
        "    area_b = (b[2] - b[0]) * (b[3] - b[1])\n",
        "    area_combined = area_a + area_b - area_overlap\n",
        "\n",
        "    iou = area_overlap / (area_combined+epsilon)\n",
        "    return iou\n",
        "\n",
        "\n",
        "def gt_pred_lists(gt_class_ids, gt_bboxes, pred_class_ids, pred_bboxes, iou_tresh = IOU_THRESHOLD):\n",
        "\n",
        "    \"\"\" \n",
        "        Given a list of ground truth and predicted classes and their boxes, \n",
        "        this function associates the predicted classes to their gt classes using a given Iou (Iou>= 0.5 for example) and returns \n",
        "        two normalized lists of len = N containing the gt and predicted classes, \n",
        "        filling the non-predicted and miss-predicted classes by the background class (index 0).\n",
        "        Args    :\n",
        "            gt_class_ids   :    list of gt classes of size N1\n",
        "            pred_class_ids :    list of predicted classes of size N2\n",
        "            gt_bboxes      :    list of gt boxes [N1, (x1, y1, x2, y2)]\n",
        "            pred_bboxes    :    list of pred boxes [N2, (x1, y1, x2, y2)]\n",
        "            \n",
        "        Returns : \n",
        "            gt             :    list of size N\n",
        "            pred           :    list of size N \n",
        "    \"\"\"\n",
        "\n",
        "    gt_class_ids_ = {'state' : [0*i for i in range(len(gt_class_ids))], \"gt_class_ids\":list(gt_class_ids)}\n",
        "    pred_class_ids_ = {'state' : [0*i for i in range(len(pred_class_ids))], \"pred_class_ids\":list(pred_class_ids)}\n",
        "\n",
        "    pred=[]\n",
        "    gt=[]\n",
        "\n",
        "    for i, gt_class in enumerate(gt_class_ids_[\"gt_class_ids\"]):\n",
        "        for j, pred_class in enumerate(pred_class_ids_['pred_class_ids']):\n",
        "            if get_iou(gt_bboxes[i], pred_bboxes[j])>=iou_tresh:\n",
        "                gt_class_ids_['state'][i] = 1\n",
        "                pred_class_ids_['state'][j] = 1\n",
        "\n",
        "                if (gt_class == pred_class):\n",
        "                    gt.append(gt_class)\n",
        "                    pred.append(pred_class)\n",
        "                else : \n",
        "                    gt.append(gt_class)\n",
        "                    pred.append(pred_class)\n",
        "                \n",
        "    for i, gt_class in enumerate(gt_class_ids_[\"gt_class_ids\"]):\n",
        "        if gt_class_ids_['state'][i] == 0:\n",
        "            gt.append(gt_class)\n",
        "            pred.append(0)\n",
        "\n",
        "    for j, pred_class in enumerate(pred_class_ids_[\"pred_class_ids\"]):\n",
        "        if pred_class_ids_['state'][j] == 0:\n",
        "            gt.append(0)\n",
        "            pred.append(pred_class)\n",
        "    return gt, pred\n",
        "\n",
        "\n",
        "def get_new_fig(fn, figsize=[9,9]):\n",
        "    \"\"\" Init graphics \"\"\"\n",
        "    fig1 = plt.figure(fn, figsize)\n",
        "    ax1 = fig1.gca()\n",
        "    ax1.cla()\n",
        "    return fig1, ax1\n",
        "\n",
        "\n",
        "def configcell_text_and_colors(array_df, lin, col, oText, facecolors, posi, fz, fmt, show_null_values=0):\n",
        "    \"\"\"\n",
        "      config cell text and colors\n",
        "      and return text elements to add and to dell\n",
        "      @TODO: use fmt\n",
        "    \"\"\"\n",
        "    text_add = []; text_del = [];\n",
        "    cell_val = array_df[lin][col]\n",
        "    tot_all = array_df[-1][-1]\n",
        "    per = (float(cell_val) / tot_all) * 100\n",
        "    curr_column = array_df[:,col]\n",
        "    ccl = len(curr_column)\n",
        "\n",
        "    if(col == (ccl - 1)) or (lin == (ccl - 1)):\n",
        "        if(cell_val != 0):\n",
        "            if(col == ccl - 1) and (lin == ccl - 1):\n",
        "                tot_rig = 0\n",
        "                for i in range(array_df.shape[0] - 1):\n",
        "                    tot_rig += array_df[i][i]\n",
        "                per_ok = (float(tot_rig) / cell_val) * 100\n",
        "            elif(col == ccl - 1):\n",
        "                tot_rig = array_df[lin][lin]\n",
        "                per_ok = (float(tot_rig) / cell_val) * 100\n",
        "            elif(lin == ccl - 1):\n",
        "                tot_rig = array_df[col][col]\n",
        "                per_ok = (float(tot_rig) / cell_val) * 100\n",
        "            per_err = 100 - per_ok\n",
        "        else:\n",
        "            per_ok = per_err = 0\n",
        "\n",
        "        per_ok_s = ['%.2f%%'%(per_ok), '100%'] [per_ok == 100]\n",
        "\n",
        "        text_del.append(oText)\n",
        "\n",
        "        font_prop = fm.FontProperties(weight='bold', size=fz)\n",
        "        text_kwargs = dict(color='w', ha=\"center\", va=\"center\", gid='sum', fontproperties=font_prop)\n",
        "        lis_txt = ['%d'%(cell_val), per_ok_s, '%.2f%%'%(per_err)]\n",
        "        lis_kwa = [text_kwargs]\n",
        "        dic = text_kwargs.copy(); dic['color'] = 'g'; lis_kwa.append(dic);\n",
        "        dic = text_kwargs.copy(); dic['color'] = 'r'; lis_kwa.append(dic);\n",
        "        lis_pos = [(oText._x, oText._y-0.3), (oText._x, oText._y), (oText._x, oText._y+0.3)]\n",
        "        for i in range(len(lis_txt)):\n",
        "            newText = dict(x=lis_pos[i][0], y=lis_pos[i][1], text=lis_txt[i], kw=lis_kwa[i])\n",
        "            text_add.append(newText)\n",
        "\n",
        "        carr = [0.27, 0.30, 0.27, 1.0]\n",
        "        if(col == ccl - 1) and (lin == ccl - 1):\n",
        "            carr = [0.17, 0.20, 0.17, 1.0]\n",
        "        facecolors[posi] = carr\n",
        "\n",
        "    else:\n",
        "        if(per > 0):\n",
        "            txt = '%s\\n%.2f%%' %(cell_val, per)\n",
        "        else:\n",
        "            if(show_null_values == 0):\n",
        "                txt = ''\n",
        "            elif(show_null_values == 1):\n",
        "                txt = '0'\n",
        "            else:\n",
        "                txt = '0\\n0.0%'\n",
        "        oText.set_text(txt)\n",
        "\n",
        "        if(col == lin):\n",
        "            oText.set_color('w')\n",
        "            facecolors[posi] = [0.35, 0.8, 0.55, 1.0]\n",
        "        else:\n",
        "            oText.set_color('r')\n",
        "\n",
        "    return text_add, text_del\n",
        "\n",
        "\n",
        "def insert_totals(df_cm):\n",
        "    \"\"\" insert total column and line (the last ones) \"\"\"\n",
        "    sum_col = []\n",
        "    for c in df_cm.columns:\n",
        "        sum_col.append( df_cm[c].sum() )\n",
        "    sum_lin = []\n",
        "    for item_line in df_cm.iterrows():\n",
        "        sum_lin.append( item_line[1].sum() )\n",
        "    df_cm['sum_lin'] = sum_lin\n",
        "    sum_col.append(np.sum(sum_lin))\n",
        "    df_cm.loc['sum_col'] = sum_col\n",
        "\n",
        "\n",
        "def pretty_plot_confusion_matrix(df_cm, annot=True, cmap=\"Oranges\", fmt='.2f', fz=11,\n",
        "      lw=0.5, cbar=False, figsize=[8,8], show_null_values=0, pred_val_axis='y'):\n",
        "    \"\"\"\n",
        "      print conf matrix with default layout (like matlab)\n",
        "      params:\n",
        "        df_cm          dataframe (pandas) without totals\n",
        "        annot          print text in each cell\n",
        "        cmap           Oranges,Oranges_r,YlGnBu,Blues,RdBu, ... see:\n",
        "        fz             fontsize\n",
        "        lw             linewidth\n",
        "        pred_val_axis  where to show the prediction values (x or y axis)\n",
        "                        'col' or 'x': show predicted values in columns (x axis) instead lines\n",
        "                        'lin' or 'y': show predicted values in lines   (y axis)\n",
        "    \"\"\"\n",
        "    if(pred_val_axis in ('col', 'x')):\n",
        "        xlbl = 'Predicted'\n",
        "        ylbl = 'Actual'\n",
        "    else:\n",
        "        xlbl = 'Actual'\n",
        "        ylbl = 'Predicted'\n",
        "        df_cm = df_cm.T\n",
        "\n",
        "    insert_totals(df_cm)\n",
        "\n",
        "    fig, ax1 = get_new_fig('Conf matrix default', figsize)\n",
        "\n",
        "    sn.set(font_scale=1.8)\n",
        "    ax = sn.heatmap(df_cm, annot=annot, annot_kws={\"size\": fz}, linewidths=lw, ax=ax1,\n",
        "                    cbar=cbar, cmap=cmap, linecolor='w', fmt=fmt)\n",
        "    \n",
        "\n",
        "    ax.set_xticklabels(ax.get_xticklabels(), rotation = 75, fontsize = 26)\n",
        "    ax.set_yticklabels(ax.get_yticklabels(), rotation = 25, fontsize = 26)\n",
        "\n",
        "    for t in ax.xaxis.get_major_ticks():\n",
        "        t.tick1On = False\n",
        "        t.tick2On = False\n",
        "    for t in ax.yaxis.get_major_ticks():\n",
        "        t.tick1On = False\n",
        "        t.tick2On = False\n",
        "\n",
        "    quadmesh = ax.findobj(QuadMesh)[0]\n",
        "    facecolors = quadmesh.get_facecolors()\n",
        "\n",
        "    array_df = np.array( df_cm.to_records(index=False).tolist() )\n",
        "    text_add = []; text_del = [];\n",
        "    posi = -1\n",
        "    for t in ax.collections[0].axes.texts:\n",
        "        pos = np.array( t.get_position()) - [0.5,0.5]\n",
        "        lin = int(pos[1]); col = int(pos[0]);\n",
        "        posi += 1\n",
        "\n",
        "        txt_res = configcell_text_and_colors(array_df, lin, col, t, facecolors, posi, fz, fmt, show_null_values)\n",
        "\n",
        "        text_add.extend(txt_res[0])\n",
        "        text_del.extend(txt_res[1])\n",
        "\n",
        "    for item in text_del:\n",
        "        item.remove()\n",
        "    for item in text_add:\n",
        "        ax.text(item['x'], item['y'], item['text'], **item['kw'])\n",
        "\n",
        "    ax.set_title('Confusion matrix')\n",
        "    ax.set_xlabel(xlbl)\n",
        "    ax.set_ylabel(ylbl)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_confusion_matrix_from_data(y_test, predictions, columns=None, annot=True, cmap=\"Oranges\",\n",
        "      fmt='.2f', fz=11, lw=0.5, cbar=False, figsize=[36,36], show_null_values=0, pred_val_axis='lin'):\n",
        "    \"\"\"\n",
        "        plot confusion matrix function with y_test (actual values) and predictions (predic),\n",
        "        whitout a confusion matrix yet\n",
        "        return the tp, fp and fn\n",
        "    \"\"\"\n",
        "\n",
        "    if(not columns):\n",
        "        columns = ['class %s' %(i) for i in list(ascii_uppercase)[0:max(len(np.unique(y_test)),len(np.unique(predictions)))]]\n",
        "    \n",
        "    y_test = np.array(y_test)\n",
        "    predictions = np.array(predictions)\n",
        "    confm = confusion_matrix(y_test, predictions)\n",
        "    num_classes = len(columns)\n",
        "    \n",
        "    fp=[0]*num_classes\n",
        "    fn=[0]*num_classes\n",
        "    tp=[0]*num_classes\n",
        "    for i in range(confm.shape[0]):\n",
        "        fn[i]+=np.sum(confm[i])-np.diag(confm)[i]\n",
        "        fp[i]+=np.sum(np.transpose(confm)[i])-np.diag(confm)[i]\n",
        "        for j in range(confm.shape[1]):\n",
        "            if i==j:\n",
        "                tp[i]+=confm[i][j]\n",
        "    \n",
        "    df_cm = DataFrame(confm, index=columns, columns=columns)\n",
        "\n",
        "    pretty_plot_confusion_matrix(df_cm, fz=fz, cmap=cmap, figsize=figsize, show_null_values=show_null_values, \n",
        "        pred_val_axis=pred_val_axis, lw=lw, fmt=fmt)\n",
        "    \n",
        "    return tp, fp, fn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVyzRu3PxLaa"
      },
      "source": [
        "### Confusion Matrix usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HFVtCP_qYo8"
      },
      "outputs": [],
      "source": [
        "#supose we have 1 image containing the gt classes bellow :\n",
        "# gt_class_id = np.array([1,2,3,1,2,3])\n",
        "#with the bbox :\n",
        "# gt_bbox = np.array([np.array([10,100,20,200]),np.array([100,10,200,20]),np.array([110,15,220,25]),np.array([20,200,20,200]),np.array([90,15,220,20]),np.array([100,10,150,20])])\n",
        "#and the model detected the classes : \n",
        "pred_class_id = results[0][\"class_ids\"]\n",
        "#with the bbox : \n",
        "pred_bbox = results[0][\"rois\"]\n",
        "\n",
        "#for this image, the gt and pred lists are:\n",
        "gt_tot = np.array([])\n",
        "pred_tot = np.array([])\n",
        " \n",
        "gt, pred = gt_pred_lists(gt_class_id, gt_bbox, pred_class_id, pred_bbox)\n",
        "gt_tot = np.append(gt_tot, gt)\n",
        "pred_tot = np.append(pred_tot, pred)\n",
        "\n",
        "#here i didnt set the columns list, since in the code if columns is note specified \n",
        "#it generates automatically a list from \"class A\" to \"class ..\". in this example, class A should be the background\n",
        "#Note : class A is the backround in this example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xh-cZCajrMZT"
      },
      "outputs": [],
      "source": [
        "tp, fp, fn = plot_confusion_matrix_from_data(gt_tot,pred_tot,fz=18, figsize=(15,15), lw=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGOox8xD04wz"
      },
      "outputs": [],
      "source": [
        "print(\"True Positives:\", tp)\n",
        "print(\"False Positives:\", fp)\n",
        "print(\"False Negatives:\", fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcCJ8YTCeyQi"
      },
      "source": [
        "## Intersection Over Union"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ib5pJXg3SZJA"
      },
      "outputs": [],
      "source": [
        "# Compute VOC-Style mAP\n",
        "def calculate_mAP(dataset):\n",
        "    APs = []\n",
        "\n",
        "    for image_id in dataset.image_ids:\n",
        "        # Load image and ground truth data\n",
        "        image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "            modellib.load_image_gt(dataset, inference_config,\n",
        "                                image_id, use_mini_mask=False)\n",
        "        molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
        "        # Run object detection\n",
        "        results = model.detect([image], verbose=0)\n",
        "        r = results[0]\n",
        "        # Compute AP\n",
        "        AP, precisions, recalls, overlaps = utils.compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'], iou_threshold=IOU_THRESHOLD)\n",
        "        APs.append(AP)\n",
        "        \n",
        "    return APs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sk9pBqI011UF"
      },
      "outputs": [],
      "source": [
        "image_val_APs = calculate_mAP(dataset_val)\n",
        "#image_train_APs = calculate_mAP(dataset_train)\n",
        "\n",
        "#APs = np.concatenate((image_train_APs, image_val_APs))\n",
        "\n",
        "mAP = np.mean(image_val_APs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eetbs3ngxjRc"
      },
      "outputs": [],
      "source": [
        "print(\"mAP: \", mAP)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "WojeZdwRxEU1"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}